{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport nibabel as nib\nimport os,glob,cv2,re,json,numbers\nimport pylab as plt\nimport pandas as pd\nfrom pathlib import *\nfrom scipy import ndimage\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import layers, Input\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom tensorflow.keras.layers import Conv3D, MaxPooling3D\nfrom tensorflow.keras.layers import BatchNormalization, Dropout, Activation\nfrom tensorflow.keras.layers import Dense, Flatten, Input\nfrom keras.layers.merge import add\nfrom keras.regularizers import l2\nkernel_regularizer=l2(1e-4)","metadata":{"execution":{"iopub.status.busy":"2022-10-16T14:50:11.114061Z","iopub.execute_input":"2022-10-16T14:50:11.114329Z","iopub.status.idle":"2022-10-16T14:50:17.555277Z","shell.execute_reply.started":"2022-10-16T14:50:11.114244Z","shell.execute_reply":"2022-10-16T14:50:17.554367Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def read_nifti_file(filepath):\n    scan = nib.load(filepath)\n    scan = scan.get_fdata()\n    return scan\n\n\ndef normalize(volume):\n    min = -200\n    max = 1200\n    #float(volume.min())= min\n    #float(volume.max()) = max\n    #volume = (volume - min) / (max - min)\n    #volume = volume.astype(\"float32\")\n    volume = np.floor((volume - min) / (max - min))\n    return volume\n\n\ndef resize_volume(img):\n    desired_depth = 64\n    desired_width = 128\n    desired_height = 128\n    current_depth = img.shape[-1]\n    current_width = img.shape[0]\n    current_height = img.shape[1]\n    depth = current_depth / desired_depth\n    width = current_width / desired_width\n    height = current_height / desired_height\n    depth_factor = 1 / depth\n    width_factor = 1 / width\n    height_factor = 1 / height\n    img = ndimage.rotate(img, 90, reshape=False)\n    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)\n    return img\n\n\ndef process_scan(path):\n    volume = read_nifti_file(path)\n    volume = normalize(volume)\n    volume = resize_volume(volume)\n    return volume","metadata":{"execution":{"iopub.status.busy":"2022-10-16T14:50:17.557107Z","iopub.execute_input":"2022-10-16T14:50:17.557363Z","iopub.status.idle":"2022-10-16T14:50:17.568668Z","shell.execute_reply.started":"2022-10-16T14:50:17.557327Z","shell.execute_reply":"2022-10-16T14:50:17.568040Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"glob_path_control = glob.glob(r\"../input/parkinson/taowu/sub-control*/anat/*.nii\")\n\nglob_path_patient = glob.glob(r\"../input/parkinson/taowu/sub-patient*/anat/*.nii\")\n\ncontrol_data = np.array([process_scan(path) for path in glob_path_control])\npatient_data = np.array([process_scan(path) for path in glob_path_patient])\n\n\ncontrol_labels = np.array([1 for _ in range(len(control_data))])\npatient_labels = np.array([0 for _ in range(len(patient_data))])\n\n\nX = np.concatenate((control_data, patient_data), axis=0)\nprint(\"Dataset Shape : \", X.shape)\nY = np.concatenate((control_labels, patient_labels), axis=0)\nprint(\"Label Shape : \", Y.shape)","metadata":{"execution":{"iopub.status.busy":"2022-10-16T14:50:17.570024Z","iopub.execute_input":"2022-10-16T14:50:17.570335Z","iopub.status.idle":"2022-10-16T14:51:06.687213Z","shell.execute_reply.started":"2022-10-16T14:50:17.570288Z","shell.execute_reply":"2022-10-16T14:51:06.686424Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Dataset Shape :  (40, 128, 128, 64)\nLabel Shape :  (40,)\n","output_type":"stream"}]},{"cell_type":"code","source":"Y = to_categorical(Y)\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=42)\nprint(\"X_train : \", X_train.shape)\nprint(\"X_test : \", X_test.shape)\nprint(\"Y_train : \", Y_train.shape)\nprint(\"Y_test : \", Y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-10-16T14:51:06.689274Z","iopub.execute_input":"2022-10-16T14:51:06.689697Z","iopub.status.idle":"2022-10-16T14:51:06.798505Z","shell.execute_reply.started":"2022-10-16T14:51:06.689658Z","shell.execute_reply":"2022-10-16T14:51:06.797673Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"X_train :  (32, 128, 128, 64)\nX_test :  (8, 128, 128, 64)\nY_train :  (32, 2)\nY_test :  (8, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"import random\nfrom scipy import ndimage\n@tf.function\ndef rotate(volume):\n    \"\"\"Rotate the volume by a few degrees\"\"\"\n\n    def scipy_rotate(volume):\n        # define some rotation angles\n        angles = [-20, -10, -5, 5, 10, 20]\n        # pick angles at random\n        angle = random.choice(angles)\n        # rotate volume\n        volume = ndimage.rotate(volume, angle, reshape=False)\n        volume[volume < 0] = 0\n        volume[volume > 1] = 1\n        return volume\n\n    augmented_volume = tf.numpy_function(scipy_rotate, [volume], tf.float32)\n    return augmented_volume\n\n\ndef train_preprocessing(volume, label):\n    \"\"\"Process training data by rotating and adding a channel.\"\"\"\n    # Rotate volume\n    volume = rotate(volume)\n    volume = tf.expand_dims(volume, axis=3)\n    return volume, label\n\n\ndef validation_preprocessing(volume, label):\n    \"\"\"Process validation data by only adding a channel.\"\"\"\n    volume = tf.expand_dims(volume, axis=3)\n    return volume, label","metadata":{"execution":{"iopub.status.busy":"2022-10-16T14:51:06.799936Z","iopub.execute_input":"2022-10-16T14:51:06.800230Z","iopub.status.idle":"2022-10-16T14:51:06.811253Z","shell.execute_reply.started":"2022-10-16T14:51:06.800192Z","shell.execute_reply":"2022-10-16T14:51:06.810065Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_loader = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\nvalidation_loader = tf.data.Dataset.from_tensor_slices((X_test, Y_test))\n\nbatch_size = 2\n# Augment the on the fly during training.\ntrain_dataset = (\n    train_loader.shuffle(len(X_train))\n    .map(train_preprocessing)\n    .batch(batch_size)\n    .prefetch(2)\n)\n# Only rescale.\nvalidation_dataset = (\n    validation_loader.shuffle(len(X_test))\n    .map(validation_preprocessing)\n    .batch(batch_size)\n    .prefetch(2)\n)","metadata":{"execution":{"iopub.status.busy":"2022-10-16T14:51:48.471675Z","iopub.execute_input":"2022-10-16T14:51:48.471935Z","iopub.status.idle":"2022-10-16T14:51:49.120999Z","shell.execute_reply.started":"2022-10-16T14:51:48.471905Z","shell.execute_reply":"2022-10-16T14:51:49.120252Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"nb_class = 2\nopt = 'adam'\nclassifier = 'sigmoid'\nloss_function = 'binary_crossentropy'\n\n\ndef get_model(width=128, height=128, depth=64, channel = 1):\n\n    inputs = Input((width, height, depth, channel))\n    \n \n    conv1 = Conv3D(filters=32, kernel_size=(5, 5, 5),\n                           strides=(2,2,2), padding=\"same\",\n                           kernel_initializer=\"he_normal\",\n                           kernel_regularizer=kernel_regularizer\n                           )(inputs)\n    print(conv1.shape)\n    conv11 = Conv3D(filters=32, kernel_size=(5, 5, 5),\n                           strides=(1,1,1), padding=\"same\",\n                           kernel_initializer=\"he_normal\",\n                           kernel_regularizer=kernel_regularizer\n                           )(conv1)\n    norm1 = BatchNormalization(axis=-1)(conv11)\n    relu1 = Activation(\"relu\")(norm1)\n    print(relu1.shape)\n    residual1 = Conv3D(filters=32, kernel_size=(3, 3, 3),\n                           strides=(1,1,1), padding=\"same\",\n                           kernel_initializer=\"he_normal\",\n                           kernel_regularizer=kernel_regularizer\n                           )(relu1)\n    print(residual1.shape)\n    resblock1 = add([conv1, residual1])\n    \n    conv2 = Conv3D(filters=64, kernel_size=(5, 5, 5),\n                           strides=(2,2,2), padding=\"same\",\n                           kernel_initializer=\"he_normal\",\n                           kernel_regularizer=kernel_regularizer\n                           )(resblock1)\n    \n    conv22 = Conv3D(filters=64, kernel_size=(5, 5, 5),\n                           strides=(1,1,1), padding=\"same\",\n                           kernel_initializer=\"he_normal\",\n                           kernel_regularizer=kernel_regularizer\n                           )(conv2)\n    norm2 = BatchNormalization(axis=-1)(conv22)\n    relu2 = Activation(\"relu\")(norm2)\n    print(relu1.shape)\n    residual2 = Conv3D(filters=64, kernel_size=(3, 3, 3),\n                           strides=(1,1,1), padding=\"same\",\n                           kernel_initializer=\"he_normal\",\n                           kernel_regularizer=kernel_regularizer\n                           )(relu2)\n    print(residual1.shape)\n    resblock2 = add([conv2, residual2])\n    \n    \n    conv3 = Conv3D(filters=64, kernel_size=(3, 3, 3),\n                           strides=(2,2,2), padding=\"same\",\n                           kernel_initializer=\"he_normal\",\n                           kernel_regularizer=kernel_regularizer\n                           )(resblock2)\n    \n    conv33 = Conv3D(filters=128, kernel_size=(3, 3, 3),\n                           strides=(1,1,1), padding=\"same\",\n                           kernel_initializer=\"he_normal\",\n                           kernel_regularizer=kernel_regularizer\n                           )(conv3)\n    norm3 = BatchNormalization(axis=-1)(conv3)\n    relu3 = Activation(\"relu\")(norm3)\n    print(relu1.shape)\n    residual3 = Conv3D(filters=64, kernel_size=(3, 3, 3),\n                           strides=(1,1,1), padding=\"same\",\n                           kernel_initializer=\"he_normal\",\n                           kernel_regularizer=kernel_regularizer\n                           )(relu3)\n    print(residual1.shape)\n    resblock3 = add([conv3, residual3])\n    \n    conv4 = Conv3D(filters=16, kernel_size=(3, 3, 3),\n                           strides=(2,2,2), padding=\"same\",\n                           kernel_initializer=\"he_normal\",\n                           kernel_regularizer=kernel_regularizer\n                           )(resblock3)\n    \n    conv44 = Conv3D(filters=16, kernel_size=(3, 3, 3),\n                           strides=(1,1,1), padding=\"same\",\n                           kernel_initializer=\"he_normal\",\n                           kernel_regularizer=kernel_regularizer\n                           )(conv4)\n    norm4 = BatchNormalization(axis=-1)(conv44)\n    relu4 = Activation(\"relu\")(norm4)\n    print(relu1.shape)\n    residual4 = Conv3D(filters=16, kernel_size=(3, 3, 3),\n                           strides=(1,1,1), padding=\"same\",\n                           kernel_initializer=\"he_normal\",\n                           kernel_regularizer=kernel_regularizer\n                           )(relu4)\n    print(residual1.shape)\n    resblock4 = add([conv4, residual4])\n    \n    conv5 = Conv3D(filters=16, kernel_size=(3, 3, 3),\n                           strides=(2,2,1), padding=\"same\",\n                           kernel_initializer=\"he_normal\",\n                           kernel_regularizer=kernel_regularizer\n                           )(resblock4)\n    \n    x = MaxPooling3D(pool_size=(2,2,2), strides=(2, 2, 2))(conv5)\n    y = Flatten()(x)\n    outputs = Dense(units=nb_class, activation=classifier,\n                    kernel_initializer ='he_normal')(y)\n    \n  \n    model = Model(inputs, outputs, name=\"Resnet\")\n    \n    return model\n\n\nmodel = get_model(width=128, height=128, depth=64, channel =1)\n\n#print(model.summary())","metadata":{"execution":{"iopub.status.busy":"2022-10-16T14:52:08.120402Z","iopub.execute_input":"2022-10-16T14:52:08.120667Z","iopub.status.idle":"2022-10-16T14:52:08.279199Z","shell.execute_reply.started":"2022-10-16T14:52:08.120637Z","shell.execute_reply":"2022-10-16T14:52:08.278257Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"(None, 64, 64, 32, 32)\n(None, 64, 64, 32, 32)\n(None, 64, 64, 32, 32)\n(None, 64, 64, 32, 32)\n(None, 64, 64, 32, 32)\n(None, 64, 64, 32, 32)\n(None, 64, 64, 32, 32)\n(None, 64, 64, 32, 32)\n(None, 64, 64, 32, 32)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Compile model.\ninitial_learning_rate = 0.0001\nlr_schedule = keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n)\nmodel.compile(\n    loss=\"binary_crossentropy\",\n    optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n    metrics=[\"acc\"],\n)\n\n# Define callbacks.\ncheckpoint_cb = keras.callbacks.ModelCheckpoint(\n    \"3d_image_classification.h5\", save_best_only=True\n)\nearly_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_acc\", patience=15)\n\n# Train the model, doing validation at the end of each epoch\nepochs = 100\nmodel.fit(\n    train_dataset,\n    validation_data=validation_dataset,\n    epochs=epochs,\n    shuffle=True,\n    verbose=2,\n    callbacks=[checkpoint_cb, early_stopping_cb],\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-10-16T14:52:51.493361Z","iopub.execute_input":"2022-10-16T14:52:51.493955Z","iopub.status.idle":"2022-10-16T14:52:53.420498Z","shell.execute_reply.started":"2022-10-16T14:52:51.493920Z","shell.execute_reply":"2022-10-16T14:52:53.418314Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Epoch 1/100\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/4236615137.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint_cb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_cb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m )\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument:  0-th value returned by pyfunc_0 is double, but expects float\n\t [[{{node StatefulPartitionedCall/PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[gradient_tape/binary_crossentropy/logistic_loss/mul/Shape_1/_6]]\n  (1) Invalid argument:  0-th value returned by pyfunc_0 is double, but expects float\n\t [[{{node StatefulPartitionedCall/PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_5510]\n\nFunction call stack:\ntrain_function -> train_function\n"],"ename":"InvalidArgumentError","evalue":"2 root error(s) found.\n  (0) Invalid argument:  0-th value returned by pyfunc_0 is double, but expects float\n\t [[{{node StatefulPartitionedCall/PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[gradient_tape/binary_crossentropy/logistic_loss/mul/Shape_1/_6]]\n  (1) Invalid argument:  0-th value returned by pyfunc_0 is double, but expects float\n\t [[{{node StatefulPartitionedCall/PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_5510]\n\nFunction call stack:\ntrain_function -> train_function\n","output_type":"error"}]},{"cell_type":"code","source":"model.compile(optimizer = opt,\n                loss = loss_function,\n                metrics = ['accuracy'])\nhistory = model.fit(train_dataset, validation_dataset, \n                         batch_size = 64, \n                         verbose = 1, \n                         epochs = 90,      \n                         validation_data=(X_test,Y_test),\n                         shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2022-10-16T14:52:02.907844Z","iopub.execute_input":"2022-10-16T14:52:02.908434Z","iopub.status.idle":"2022-10-16T14:52:02.941840Z","shell.execute_reply.started":"2022-10-16T14:52:02.908396Z","shell.execute_reply":"2022-10-16T14:52:02.940697Z"},"trusted":true},"execution_count":11,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/417461879.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                          \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                          \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                          shuffle = True)\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1146\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1381\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1383\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, steps, **kwargs)\u001b[0m\n\u001b[1;32m    706\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_user_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_validate_args\u001b[0;34m(self, y, sample_weights, steps)\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[0;31m# Arguments that shouldn't be passed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_none_or_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m       raise ValueError(\"`y` argument is not supported when using \"\n\u001b[0m\u001b[1;32m    742\u001b[0m                        \"dataset as input.\")\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_none_or_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: `y` argument is not supported when using dataset as input."],"ename":"ValueError","evalue":"`y` argument is not supported when using dataset as input.","output_type":"error"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nloss_and_metrics = model.evaluate(x_test, y_test, verbose=1)\nprint(\"Test Loss\", loss_and_metrics[0])\nprint(\"Test Accuracy\", loss_and_metrics[1])\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='lower right')","metadata":{"execution":{"iopub.status.busy":"2022-10-16T14:51:10.619294Z","iopub.status.idle":"2022-10-16T14:51:10.620159Z","shell.execute_reply.started":"2022-10-16T14:51:10.619897Z","shell.execute_reply":"2022-10-16T14:51:10.619922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i","metadata":{"execution":{"iopub.status.busy":"2022-10-16T14:51:10.621531Z","iopub.status.idle":"2022-10-16T14:51:10.622502Z","shell.execute_reply.started":"2022-10-16T14:51:10.622267Z","shell.execute_reply":"2022-10-16T14:51:10.622292Z"},"trusted":true},"execution_count":null,"outputs":[]}]}